# Hebrew Scripture Data Repository

This directory contains all processed Hebrew Scripture data for the Davar study app. It implements a consolidated architecture with optimized JSON files for maximum performance and minimal storage requirements.

## ğŸ“ Directory Structure

```
data/dict/
â”œâ”€â”€ README.md                    # This documentation
â”œâ”€â”€ HYBRID_SYSTEM_EXPLANATION.md # Technical system explanation
â”œâ”€â”€ README_VERSES.md            # Legacy verse documentation
â”‚
â”œâ”€â”€ lexicon/                     # ğŸ§  LEXICON DATA - Consolidated word definitions
â”‚   â”œâ”€â”€ roots.json              # All primitive roots (3,131 entries)
â”‚   â”œâ”€â”€ words.json              # All derived words (6,312 entries)
â”‚   â”œâ”€â”€ roots.pretty.json       # Pretty-printed roots (development)
â”‚   â”œâ”€â”€ words.pretty.json       # Pretty-printed words (development)
â”‚   â””â”€â”€ testing/                # Development samples (1% of data)
â”‚       â”œâ”€â”€ words/              # Test derived words
â”‚       â””â”€â”€ roots/              # Test primitive roots
â”‚
â”œâ”€â”€ books/                       # ğŸ“– BOOK DATA - Consolidated verse files
â”‚   â”œâ”€â”€ genesis.json            # Complete Genesis book
â”‚   â”œâ”€â”€ exodus.json            # Complete Exodus book
â”‚   â”œâ”€â”€ leviticus.json          # Complete Leviticus book
â”‚   â””â”€â”€ ...                     # All 33 Tanakh books (18,406 verses total)
â”‚
â””â”€â”€ raw/                        # ğŸ“š RAW SOURCE DATA - Read-only
    â”œâ”€â”€ morphus/                # BDB morphological analysis (39 XML files)
    â”‚   â”œâ”€â”€ Gen.xml            # Genesis morphology
    â”‚   â”œâ”€â”€ Exod.xml           # Exodus morphology
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ bdb_full.json           # Complete BDB dictionary
    â”œâ”€â”€ bdb_dict_en.json        # BDB English definitions
    â”œâ”€â”€ BrownDriverBriggs.xml   # Original BDB XML source
    â”œâ”€â”€ HebrewStrong.xml        # Strong's Hebrew dictionary
    â”œâ”€â”€ strongs_hebrew_dict_en.json # Strong's English definitions
    â””â”€â”€ strong_refs.json        # Strong's reference mapping
```

## ğŸ¯ System Architecture

### Consolidated Design Philosophy

**Challenge**: Managing thousands of individual files creates filesystem overhead and complicates data management.

**Solution**: Consolidated architecture:
1. **ğŸ“š Lexicon Layer** (`lexicon/`) - All word definitions in optimized JSON files
2. **ğŸ“– Book Layer** (`books/`) - Complete books with all verses in single files

### Key Benefits
- ğŸš€ **Performance**: Reduced I/O operations and filesystem overhead
- ğŸ’¾ **Efficiency**: Minified JSON saves ~40% storage space
- ğŸ”§ **Maintainability**: Simplified file management and version control
- ğŸ”„ **Flexibility**: Easy to load complete books or search entire lexicons
- ğŸ“± **Scalability**: Optimal for mobile app with reduced file count (35 vs 27,849 files)

## ğŸ“š Data Sources

### Primary Data Sources

| Source | Description | Location | Status |
|--------|-------------|----------|---------|
| **ISR Scriptures** | Hebrew Tanakh text | `../oe/` | âœ… Processed |
| **Open Scriptures MorphHB** | Morphological analysis (39 books) | `raw/morphus/` | âœ… Integrated |
| **Brown-Driver-Briggs** | Comprehensive Hebrew lexicon | `raw/BrownDriverBriggs.xml` | âœ… Processed |
| **Strong's Dictionary** | Standard Hebrew word numbering | `raw/HebrewStrong.xml` | âœ… Referenced |

### Supporting Sources

| Source | Description | Purpose |
|--------|-------------|---------|
| **TTH Translation** | Spanish translation | Multi-language support |
| **TS2009 Translation** | Hebrew transliteration | Book name standardization |
| **Custom Dictionary** | Curated 72-word definitions | Enhanced definitions |

### Data Processing Pipeline

```
ğŸ“¥ Raw Sources â”€â”€â†’ ğŸ”„ Processing Scripts â”€â”€â†’ ğŸ“¤ Processed Data
â”œâ”€â”€ ISR text         â”œâ”€â”€ build_lexicon.py      â”œâ”€â”€ lexicon/words+roots/
â”œâ”€â”€ BDB XML          â”œâ”€â”€ build_verses.py       â””â”€â”€ verses/*/
â”œâ”€â”€ Morphus XML      â””â”€â”€ qa.py validation
â””â”€â”€ Strong's refs
```

### Processing Workflow

```
ğŸ¯ INPUT SOURCES                    ğŸ”„ PROCESSING SCRIPTS                ğŸ“¤ OUTPUT DATA
â”œâ”€â”€ ISR Hebrew Text (oe/)         â”œâ”€â”€ scripts/dict/build_lexicon.py    â”œâ”€â”€ lexicon/roots.json
â”œâ”€â”€ BDB XML (raw/)                â”œâ”€â”€ scripts/dict/build_verses.py     â”œâ”€â”€ lexicon/words.json
â”œâ”€â”€ Morphological Data (morphus/) â”œâ”€â”€ scripts/dict/temp/optimize_json.py â”œâ”€â”€ books/*.json
â”œâ”€â”€ Strong's References (raw/)    â””â”€â”€ scripts/dict/qa.py              â””â”€â”€ validation & QA
â””â”€â”€ Custom Definitions (tth/)

ğŸ“Š RESULT: 9,443 lexicon entries + 33 book files (18,406 verses)
```

## ğŸš€ Processing Scripts

**ğŸ“ Location**: All processing scripts are located in `scripts/dict/`

### 1. Verse Builder (`scripts/dict/build_verses.py`)

**Purpose**: Generates lightweight verse JSON files for all Hebrew Scripture books.

```bash
# Process ALL books (complete Tanakh)
python scripts/dict/build_verses.py

# Process specific book
python scripts/dict/build_verses.py --book genesis

# Process specific chapter
python scripts/dict/build_verses.py --book exodus --chapter 1

# Verbose output
python scripts/dict/build_verses.py --verbose
```

**Core Features:**
- ğŸ“– Processes all 39 Tanakh books automatically
- ğŸ” Integrates BDB morphological analysis from `raw/morphus/`
- ğŸ”¢ Extracts and validates Strong's numbers
- ğŸ¯ Validates senses against lexicon definitions
- ğŸ’¾ Outputs optimized JSON format (~31,000 files)

### 2. Lexicon Builder (`scripts/dict/build_lexicon.py`)

**Purpose**: Builds complete Hebrew lexicon with definitions, senses, and references.

```bash
# Build ALL lexicon entries (production)
python scripts/dict/build_lexicon.py lexicon_100_percent_list.json

# Update existing entries
python scripts/dict/build_lexicon.py lexicon_100_percent_list.json --update

# Testing mode (1% sample)
python scripts/dict/build_lexicon.py lexicon_100_percent_list.json --testing

### 3. Quality Assurance (`scripts/dict/qa.py`)

**Purpose**: Validates lexicon data quality, structure, and integrity.

```bash
# Full validation
python scripts/dict/qa.py

# Quick validation
python scripts/dict/qa.py --quick
```

**Validation Checks:**
- ğŸ“ File structure and naming conventions
- ğŸ”— Cross-references between words and roots
- ğŸ“Š Strong's coverage completeness
- ğŸ“– Occurrence validation and accuracy
- ğŸ¯ Sense hierarchy validation
- ğŸ­ Definition completeness checking

# Quick validation
python3 lexicon/qa.py --quick
```

## ğŸ“„ Data Formats

### Consolidated Book Format

```json
{
  "1": {
    "1": {
      "reference": "genesis.1.1",
      "book_id": "genesis",
      "chapter": 1,
      "verse": 1,
      "hebrew_text": "×‘Ö¼Ö° ×¨Öµ××©×Ö´Ö–×™×ª ×‘Ö¼Ö¸×¨Ö¸Ö£× ×Ö±×œÖ¹×”Ö´Ö‘×™× ×ÖµÖ¥×ª ×”Ö· ×©×Ö¼Ö¸×Ö·Ö–×™Ö´× ×•Ö° ×ÖµÖ¥×ª ×”Ö¸ ×Ö¸Ö½×¨Ö¶×¥",
      "words": [
        {
          "position": 1,
          "hebrew": "×‘Ö¼Ö°×¨Öµ××©×Ö´Ö–×™×ª",
          "strong_number": "H7225",
          "sense": "1"
        }
      ]
    },
    "2": { /* verse 1.2 */ },
    "3": { /* verse 1.3 */ }
  },
  "2": { /* chapter 2 */ },
  "50": { /* chapter 50 */ }
}
```

### Consolidated Lexicon Format

**roots.json structure:**
```json
{
  "H1": {
    "strong_number": "H1",
    "lemma": "×Ö¸×‘",
    "normalized": "××‘",
    "pronunciation": "awb",
    "definitions": [/* ... */],
    "sources": {"bdb": true},
    "is_root": true
  },
  "H2": { /* next root */ },
  "H7999": { /* ×©×œ× root */ }
}
```

**words.json structure:**
```json
{
  "H7965": {
    "strong_number": "H7965",
    "lemma": "×©Ö¸××œ×•Ö¹×",
    "normalized": "×©×œ×•×",
    "pronunciation": "shaw-lome'",
    "definitions": [/* ... */],
    "sources": {"bdb": true, "strong": true},
    "root_ref": "H7999",
    "is_root": false
  },
  "H7966": { /* next word */ }
}
```

## ğŸ”„ Data Generation Workflow

### Initial Setup

1. **Verify raw data sources** are in `raw/` directory
2. **Ensure Hebrew text** is available in `../oe/` directory
3. **Check lexicon dependencies** in `lexicon/` directory

### Generate Books

```bash
# Generate all consolidated books
python scripts/dict/build_verses.py

# Verify output in books/ directory
ls books/ | wc -l  # Should show 33
```

### Generate Lexicon (if needed)

```bash
# Build complete lexicon (production)
python scripts/dict/build_lexicon.py lexicon_100_percent_list.json

# Validate quality
python scripts/dict/qa.py
```

## ğŸ“Š Statistics

| Component | Count | Notes |
|-----------|-------|-------|
| **Books** | 33 | Complete Tanakh books |
| **Verses** | 18,406 | All Tanakh verses consolidated |
| **Root Entries** | 3,131 | Primitive Hebrew roots |
| **Word Entries** | 6,312 | Derived Hebrew words |
| **Lexicon Total** | 9,443 | Complete Hebrew lexicon |
| **Storage Saved** | ~40% | Minified JSON vs individual files |
| **File Reduction** | 27,814 | From 27,849 to 35 files |

## âš ï¸ Important Notes

### Licensing Restrictions
- **ISR Text**: Attribution required, one verse per screen
- **TTH Translation**: Permission from Natanael Doldan requires manual processing
- **Raw Data**: Never modify files in `raw/` directory

### File Organization
- **`raw/`**: Source data - read-only, never modify
- **`lexicon/`**: Processed definitions - generated from raw data
- **`verses/`**: Lightweight references - generated from oe/ + morphus/

### Dependencies
- Python 3.8+
- XML parsing libraries (built-in)
- JSON processing (built-in)
- Path manipulation (pathlib)

## ğŸ”§ Troubleshooting

### Common Issues

**"Morphus directory not found"**
- Ensure `raw/morphus/` contains XML files
- Check file permissions

**"Book not found in mapping"**
- Verify book name spelling
- Check available books in `BookMapper.BOOK_MAPPING`

**"Lexicon validation failed"**
- Run `python scripts/dict/qa.py` for detailed diagnostics
- Check `lexicon/testing/` for sample data

### Data Validation

```bash
# Quick validation
python scripts/dict/qa.py --quick

# Full validation
python scripts/dict/qa.py

# Test verse generation
python scripts/dict/build_verses.py --book genesis --chapter 1 --verbose
```

## ğŸ“ Development Guidelines

### Data Management
- **ğŸ”’ Raw sources** (`raw/`) - Never modify, read-only reference data
- **ğŸ“¤ Generated data** (`verses/`, `lexicon/words+roots/`) - Can be committed to version control
- **ğŸ§ª Testing data** (`lexicon/testing/`) - Development only, exclude from commits
- **ğŸ”§ Scripts** (`scripts/dict/`) - Processing tools and utilities

### Production Workflow
```bash
# 1. Build consolidated lexicon
python scripts/dict/build_lexicon.py lexicon_100_percent_list.json

# 2. Generate consolidated books
python scripts/dict/build_verses.py

# 3. Optimize JSON files (optional, for production)
python scripts/dict/temp/optimize_json.py --minify

# 4. Quality assurance
python scripts/dict/qa.py
```

### Development Workflow
```bash
# Test with small sample
python scripts/dict/build_lexicon.py lexicon_100_percent_list.json --testing

# Validate and iterate
python scripts/dict/qa.py --quick
```

---

*Last updated: December 29, 2025 - Consolidated Architecture*

*Hebrew Scripture Data Repository - Core data for the Davar study app. Balancing technical excellence with spiritual sensitivity for deep engagement with sacred texts.*
